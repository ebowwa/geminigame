SOTA ML has changed video generating models are approaching, its likely in the near future you will be wearing a headgear mixed reality attachment like Vision Pro, Occulus, NReals, etc. and a model will generate digital additions onto your reality, how can you channel this?

# refactor base pygame importing
# add physics functions
# add assets
# add LLM integrations, LLM control


- AI create live assets
- AI mimic physics
- AI accessible endpoints
  